{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is Multiple Linear Regression (MLR)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"First.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Image1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regression (MLR), also known simply as multiple regression,\n",
    "is a statistical technique that uses several dependent or explanatory variables \n",
    "to predict the outcome of an Independentvariable.\n",
    "b0 ,b1, b2, b3... are the regression coefficients for the inpendent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With simple linear regression, there are only two regression coefficients - b0 and b1.\n",
    "There are only two normal equations. Finding a least-squares solution involves solving\n",
    "two equations with two unknowns - a task that is easily managed with ordinary algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multiple regression, things get more complicated. There are k independent variables and k + 1 regression coefficients. There are k + 1 normal equations. Finding a least-squares solution involves solving k + 1 equations with k + 1 unknowns. This can be done with ordinary algebra, but it is unwieldy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below equations are formulated using Ordinary Least Square Method\n",
    "<img src=\"Linear_Equation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Error.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Infrastructure Spend Country     Profit\n",
      "0   165349.2       136897.80             471784.10      US  192261.83\n",
      "1   162597.7       151377.59             443898.53      UK  191792.06\n"
     ]
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "dataset=pd.read_csv('Data1.csv')\n",
    "print(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Infrastructure Spend</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667633</td>\n",
       "      <td>0.976422</td>\n",
       "      <td>0.899008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administration</th>\n",
       "      <td>0.667633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669849</td>\n",
       "      <td>0.338165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infrastructure Spend</th>\n",
       "      <td>0.976422</td>\n",
       "      <td>0.669849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profit</th>\n",
       "      <td>0.899008</td>\n",
       "      <td>0.338165</td>\n",
       "      <td>0.813424</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      R&D Spend  Administration  Infrastructure Spend  \\\n",
       "R&D Spend              1.000000        0.667633              0.976422   \n",
       "Administration         0.667633        1.000000              0.669849   \n",
       "Infrastructure Spend   0.976422        0.669849              1.000000   \n",
       "Profit                 0.899008        0.338165              0.813424   \n",
       "\n",
       "                        Profit  \n",
       "R&D Spend             0.899008  \n",
       "Administration        0.338165  \n",
       "Infrastructure Spend  0.813424  \n",
       "Profit                1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=dataset.iloc[:,:-1].values # all except Profit column\n",
    "y=dataset.iloc[:,4].values # only profit column\n",
    "dataset[:][:4].corr() # checking correlation between independent variables (features)\n",
    "# print(X)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165349.2 136897.8 471784.1 2]\n",
      " [162597.7 151377.59 443898.53 1]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05\n",
      "  4.7178410e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05\n",
      "  4.4389853e+05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\1000267332\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\1000267332\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Encoding the categorical data\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "labelEncoder_X=LabelEncoder() # this is to convert our country column to ordinal format [1,2,3,2,3,1,2,3,2]\n",
    "X[:,3]=labelEncoder_X.fit_transform(X[:,3])\n",
    "print(X[:][:2]) #printing 2 rows\n",
    "oneHotEncoder=OneHotEncoder(categorical_features=[3])\n",
    "X=oneHotEncoder.fit_transform(X).toarray() # once we have column in ordinal format, will convert to Nominal format [[1,0,0],[0,1,0],[...]]\n",
    "print(X[:][:2]) #printing 2 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.59284160e+02 1.65865321e+03 7.73467193e-01 3.28845975e-02\n",
      " 3.66100259e-02]\n",
      "41594.8834576995\n"
     ]
    }
   ],
   "source": [
    "#avoiding dummy variable trap\n",
    "#The Dummy Variable trap is a scenario in which the independent variables are multicollinear - a scenario in which \n",
    "#two or more variables are highly correlated; in simple terms one variable can be predicted from the others.\n",
    "X=X[:,1:] #example [cat, dog]--> if not cat then obviosly dog. so we will predict only cat, else case is dog \n",
    "\n",
    "#Splitting into training and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "#fitting multuiple regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "print(regressor.coef_)\n",
    "print(regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103015.20159796 132582.27760814 132447.73845175  71976.09851259\n",
      " 178537.48221055 116161.24230166  67851.69209678  98791.73374688\n",
      " 113969.43533013 167921.06569551]\n"
     ]
    }
   ],
   "source": [
    "#predicting the test set result\n",
    "y_pred=regressor.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.948\n",
      "Model:                            OLS   Adj. R-squared:                  0.943\n",
      "Method:                 Least Squares   F-statistic:                     205.0\n",
      "Date:                Sat, 28 Nov 2020   Prob (F-statistic):           2.90e-28\n",
      "Time:                        17:05:59   Log-Likelihood:                -526.75\n",
      "No. Observations:                  50   AIC:                             1064.\n",
      "Df Residuals:                      45   BIC:                             1073.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       2.785e+04   3251.266      8.565      0.000    2.13e+04    3.44e+04\n",
      "x1          2.785e+04   3251.266      8.565      0.000    2.13e+04    3.44e+04\n",
      "x2         -1091.1075   3377.087     -0.323      0.748   -7892.910    5710.695\n",
      "x3         -1130.4509   3344.220     -0.338      0.737   -7866.055    5605.154\n",
      "x4             0.8609      0.031     27.665      0.000       0.798       0.924\n",
      "x5            -0.0527      0.050     -1.045      0.301      -0.154       0.049\n",
      "==============================================================================\n",
      "Omnibus:                       14.275   Durbin-Watson:                   1.197\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               19.260\n",
      "Skew:                          -0.953   Prob(JB):                     6.57e-05\n",
      "Kurtosis:                       5.369   Cond. No.                     1.09e+17\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 9.07e-23. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#building the optimal model using backward elimination\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.regression.linear_model as lm\n",
    "X=np.append(arr=np.ones((50,1)).astype(int),values=X,axis=1)\n",
    "X_opt=X[:,[0,1,2,3,4,5]]\n",
    "\n",
    "regressor_OLS=lm.OLS(endog=y,exog=X_opt).fit() # OLS= ordinary least square\n",
    "print(regressor_OLS.summary())\n",
    "\n",
    "# #eliminating x1 from X, removimg first column\n",
    "# X_opt = X[:, [0, 2, 3, 4, 5]]\n",
    "# regressor_OLS=lm.OLS(endog=y,exog=X_opt).fit() # OLS= ordinary least square\n",
    "# # # print(regressor_OLS.summary())\n",
    "\n",
    "# #eliminating x2 from X, removimg second column\n",
    "# X_opt = X[:, [0, 3, 4, 5]]\n",
    "# regressor_OLS=lm.OLS(endog=y,exog=X_opt).fit() # OLS= ordinary least square\n",
    "# # print(regressor_OLS.summary())\n",
    "\n",
    "# #eliminating x4 from X, removimg fourth column\n",
    "# X_opt = X[:, [0, 3, 5]]\n",
    "# regressor_OLS=lm.OLS(endog=y,exog=X_opt).fit() # OLS= ordinary least square\n",
    "# # print(regressor_OLS.summary())\n",
    "\n",
    "# #eliminating x5 from X, removimg fifth column\n",
    "# X_opt = X[:, [0, 3]]\n",
    "# regressor_OLS=lm.OLS(endog=y,exog=X_opt).fit() # OLS= ordinary least square\n",
    "# print(regressor_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
